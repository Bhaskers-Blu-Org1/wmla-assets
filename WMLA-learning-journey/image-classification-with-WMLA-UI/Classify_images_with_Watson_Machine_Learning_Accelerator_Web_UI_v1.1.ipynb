{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer vision image classification with WMLA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "- [Introduction](#Introduction)\n",
    "- [Download dataset and model](#Download-dataset-model)\n",
    "- [Import dataset](#Import-dataset)\n",
    "- [Build the model](#Build-the-model)\n",
    "- [Run Training](#Run-training)\n",
    "- [Inspect Training Run](#Inspect-training-run)\n",
    "- [Tune Hyper-parameter](#Tune-hyper-parameter)\n",
    "- [Create an inference model](#Create-an-inference-model)\n",
    "- [Test it out](#Test-it-out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "[Back to top](#Contents)\n",
    "\n",
    "This notebook details the process of performing a basic computer vision image classification example using the Deep Learning Impact functionality within Watson Machine Learning Accelerator.  \n",
    "\n",
    "Please visit [Watson Machine Learning Accelerator Learning Path](https://developer.ibm.com/series/learning-path-get-started-with-watson-machine-learning-accelerator/) for further insight of Watson ML Accelerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset and model\n",
    "\n",
    "<a id='Download-dataset-model'></a>\n",
    "[Back to top](#Contents)\n",
    "\n",
    "\n",
    "### Download dataset\n",
    "Lets get started and download the dataset from github!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'CIFAR-10-images'...\n",
      "remote: Enumerating objects: 60027, done.\u001b[K\n",
      "remote: Total 60027 (delta 0), reused 0 (delta 0), pack-reused 60027\u001b[K\n",
      "Receiving objects: 100% (60027/60027), 19.94 MiB | 23.21 MiB/s, done.\n",
      "Resolving deltas: 100% (59990/59990), done.\n",
      "Checking out files: 100% (60001/60001), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/YoongiKim/CIFAR-10-images.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/software/wmla-p10a117/wmla_sigs/notebooks/b0p052-spark231/b0p052-spark231/ac5f2d98-4517-4103-8d23-a58936a6b74c/Jupyter-5-4-0-26/config/CIFAR-10-images/train\n"
     ]
    }
   ],
   "source": [
    "cd CIFAR-10-images/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/software/wmla-p10a117/wmla_sigs/notebooks/b0p052-spark231/b0p052-spark231/ac5f2d98-4517-4103-8d23-a58936a6b74c/Jupyter-5-4-0-26/config/CIFAR-10-images/test\n"
     ]
    }
   ],
   "source": [
    "cd ../test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_path = %pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy the Dataset Training and Testing folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_path: /gpfs/software/wmla-p10a117/wmla_sigs/notebooks/b0p052-spark231/b0p052-spark231/ac5f2d98-4517-4103-8d23-a58936a6b74c/Jupyter-5-4-0-26/config/CIFAR-10-images/train\n",
      "testing_path:/gpfs/software/wmla-p10a117/wmla_sigs/notebooks/b0p052-spark231/b0p052-spark231/ac5f2d98-4517-4103-8d23-a58936a6b74c/Jupyter-5-4-0-26/config/CIFAR-10-images/test\n"
     ]
    }
   ],
   "source": [
    "print ('training_path: ' + training_path)\n",
    "print ('testing_path:' + testing_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/software/wmla-p10a117/wmla_sigs/notebooks/b0p052-spark231/b0p052-spark231/ac5f2d98-4517-4103-8d23-a58936a6b74c/Jupyter-5-4-0-26/config\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'dli-1.2.3-tensorflow-samples'...\n",
      "remote: Enumerating objects: 308, done.\u001b[K\n",
      "remote: Counting objects: 100% (308/308), done.\u001b[K\n",
      "remote: Compressing objects: 100% (227/227), done.\u001b[K\n",
      "remote: Total 539 (delta 111), reused 252 (delta 79)\u001b[K\n",
      "Receiving objects: 100% (539/539), 448.54 KiB | 0 bytes/s, done.\n",
      "Resolving deltas: 100% (212/212), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://us-south.git.cloud.ibm.com/ibmconductor-deep-learning-impact/dli-1.2.3-tensorflow-samples.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/software/wmla-p10a117/wmla_sigs/notebooks/b0p052-spark231/b0p052-spark231/ac5f2d98-4517-4103-8d23-a58936a6b74c/Jupyter-5-4-0-26/config/dli-1.2.3-tensorflow-samples/tensorflow-1.13.1/cifar10\n"
     ]
    }
   ],
   "source": [
    "cd dli-1.2.3-tensorflow-samples/tensorflow-1.13.1/cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_path: /gpfs/software/wmla-p10a117/wmla_sigs/notebooks/b0p052-spark231/b0p052-spark231/ac5f2d98-4517-4103-8d23-a58936a6b74c/Jupyter-5-4-0-26/config/dli-1.2.3-tensorflow-samples/tensorflow-1.13.1/cifar10\n"
     ]
    }
   ],
   "source": [
    "model_path = %pwd\n",
    "print ('model_path: '+ model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset\n",
    "<a id='Import-dataset'></a>\n",
    "[Back to top](#Contents)\n",
    "\n",
    "1. Lets swtich \n",
    "1. At the top Left select **Workload** > **Spark** > **Deep Learning**\n",
    "1. Select the **Datasets** tab, and click **New**\n",
    "1. Click **Images for Object Classification**. When presented with a dialog box, provide a unique name (lets use \"Cifar10\"!!!) and select the TFRecords for 'Dataset stores images in',  and then select the folder that contains the images obtained in the previous step.  The other fields are fine to use with the default settings. When you're ready, click Create.\n",
    "\n",
    "<br>\n",
    "\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-Learning-Path/Module1:Classify_images_with_Watson_Machine_Learning_Accelerator_Web_UI/Shared-images/ImportDataset.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "\n",
    "<a id='Build-the-model'></a>\n",
    "[Back to top](#Contents)\n",
    "\n",
    "1. Select the Models tab and click **New** > **Add Location**\n",
    "1. When presented with a diaglog box,  enter following attributes:\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-Learning-Path/Module1:Classify_images_with_Watson_Machine_Learning_Accelerator_Web_UI/Shared-images/modelcreation3.png)\n",
    "<br>\n",
    "1. Select the **Tensorflow-cifar10** and click **Next**.\n",
    "\n",
    "1. When presented with a dialog box, ensure that the Training engine is set to singlenode and that the data set points to the one you just created\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-Learning-Path/Module1:Classify_images_with_Watson_Machine_Learning_Accelerator_Web_UI/Shared-images/modelcreation1.png)\n",
    "<br>\n",
    "1. Set the following parameters and click **Add**\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-Learning-Path/Module1:Classify_images_with_Watson_Machine_Learning_Accelerator_Web_UI/Shared-images/modelcreation2.png)\n",
    "<br>\n",
    "1.  The model is now ready to be trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training\n",
    "\n",
    "<a id='Run-training'></a>\n",
    "[Back to top](#Contents)\n",
    "\n",
    "1. Back at the **Models** tab, select the model you created in previous step and click **Train**\n",
    "1. When presented with a dialog box, keep default parameter and click **Start Training**\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-Learning-Path/Module1:Classify_images_with_Watson_Machine_Learning_Accelerator_Web_UI/Shared-images/modeltrain1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Training Run\n",
    "\n",
    "<a id='Inspect-training-run'></a>\n",
    "[Back to top](#Contents)\n",
    "\n",
    "1. From the **Train** submenu of the **Models** tab, select the model that is training by clicking the link.\n",
    "1. Navigate from the **Overview panel** to the **Training** panel, and click the most recent link. You can watch as the results roll in.\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-Learning-Path/Module1:Classify_images_with_Watson_Machine_Learning_Accelerator_Web_UI/Shared-images/modeltrain2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Hyper-parameter\n",
    "\n",
    "<a id='Tune-hyper-parameter'></a>\n",
    "[Back to top](#Contents)\n",
    "\n",
    "1. You could search optimal hyperparameter by leveraging automated Hyper-parameter Tuning.\n",
    "1. Back at the **Models** tab, **click** on the model \n",
    "1. Navigate from the **Overview panel** to the **Hyperparameter Tuning** panel\n",
    "1. Click **New**\n",
    "1. When presented with a dialog box, enter following value and click **Start Tuning**\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-Learning-Path/Module1:Classify_images_with_Watson_Machine_Learning_Accelerator_Web_UI/Shared-images/modeltune1.png)\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-Learning-Path/Module1:Classify_images_with_Watson_Machine_Learning_Accelerator_Web_UI/Shared-images/modeltune2.png)\n",
    "1. Under the **Hyperparameter Tuning** panel, click on the hyperparameter search job \n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-Learning-Path/Module1:Classify_images_with_Watson_Machine_Learning_Accelerator_Web_UI/Shared-images/modeltune3.png)\n",
    "1. Navigate from the **Input panel** to the **Progress panel** and **Best panel** to review the optimal set of hyperparameter\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-Learning-Path/Module1:Classify_images_with_Watson_Machine_Learning_Accelerator_Web_UI/Shared-images/modeltune4.png)\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-Learning-Path/Module1:Classify_images_with_Watson_Machine_Learning_Accelerator_Web_UI/Shared-images/modeltune5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an inference model\n",
    "<a id='Create-an-inference-model'></a>\n",
    "[Back to top](#Contents)\n",
    "\n",
    "\n",
    "1. From the Training view, click Create Inference Model.\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-Learning-Path/Module1:Classify_images_with_Watson_Machine_Learning_Accelerator_Web_UI/Shared-images/inference1.png)\n",
    "1. This creates a new model in the Models tab. You can view it by going to the Inference submenu.\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-Learning-Path/Module1:Classify_images_with_Watson_Machine_Learning_Accelerator_Web_UI/Shared-images/inference2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test it out\n",
    "<a id='Test-it-out'></a>\n",
    "[Back to top](#Contents)\n",
    "\n",
    "1. Download [inference test image](https://github.com/IBM/wmla-assets/raw/master/WMLA-Learning-Path/Module1:Classify_images_with_Watson_Machine_Learning_Accelerator_Web_UI/Shared-images/car.jpg) to your laptop\n",
    "\n",
    "1. Go back to the Models tab, select the new inference model, and click Test. At the new Testing overview screen, select New Test.\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-Learning-Path/Module1:Classify_images_with_Watson_Machine_Learning_Accelerator_Web_UI/Shared-images/inference3.png)\n",
    "\n",
    "1.  When presented with a dialog box, click **Choose File** to load the inference test image.  Click **Start Test**\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-Learning-Path/Module1:Classify_images_with_Watson_Machine_Learning_Accelerator_Web_UI/Shared-images/inference4.png)\n",
    "\n",
    "1. Wait for the test state to change from RUNNING to FINISHED.  Click the link to view the results of the test.\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-Learning-Path/Module1:Classify_images_with_Watson_Machine_Learning_Accelerator_Web_UI/Shared-images/inference5.png)\n",
    "\n",
    "1. As you can see, the images are available as a thumbnail preview along with their classified label and probability.\n",
    "\n",
    "![](https://github.com/IBM/wmla-assets/raw/master/WMLA-Learning-Path/Module1:Classify_images_with_Watson_Machine_Learning_Accelerator_Web_UI/Shared-images/inference6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is version 1.0 and its content is copyright of IBM.   All rights reserved.   \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
